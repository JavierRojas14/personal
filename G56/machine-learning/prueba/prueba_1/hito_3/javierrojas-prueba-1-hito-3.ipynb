{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "import funciones_auxiliares_hito_2 as aux\n",
    "\n",
    "sns.set_style()\n",
    "plt.rcParams[\"figure.figsize\"] = (20, 10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"input/training_tweets.csv\").drop(columns=\"Unnamed: 0\")\n",
    "df[\"sentiment\"] = aux.codificar_sentimientos(df[\"sentiment\"])\n",
    "df[\"procesados_lema\"] = df.content.str.lower().apply(aux.preprocesar_texto_lema)\n",
    "df_lema = aux.obtener_100_palabras_mas_frecuentes(df[\"procesados_lema\"])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizacion"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- La optimizacion consistira en filtrar el numero de palabras segun su frecuencia. Esto permitira\n",
    "reducir la complejidad computacional, esperando tener un desempeno del modelo similar a los modelos\n",
    "sin optimizacion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "largo_df = df.shape[0]\n",
    "filtro_frecuencias = int(round(largo_df * 0.0004, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Las palabras a filtrar son:\n",
      "            palabra  conteo\n",
      "2006             ½ï      11\n",
      "2007             dh      11\n",
      "2008             pa      11\n",
      "2009           melt      11\n",
      "2010         centre      11\n",
      "...             ...     ...\n",
      "37676    hysterical       1\n",
      "37677     hypocrite       1\n",
      "37678  hypnoticzexy       1\n",
      "37679      hypnosis       1\n",
      "37680     lilmickee       1\n",
      "\n",
      "[35675 rows x 2 columns]\n",
      "\n",
      "Se pasara de 37681 a 2006 palabras\n"
     ]
    }
   ],
   "source": [
    "palabras_a_filtrar = df_lema.query(\"conteo < @filtro_frecuencias\")\n",
    "palabras_restantes = df_lema.query(\"conteo >= @filtro_frecuencias\")\n",
    "cambio_en_palabras = df_lema.shape[0] - palabras_a_filtrar.shape[0]\n",
    "LISTA_PALABRAS_A_DEJAR = set(palabras_restantes.palabra.to_list())\n",
    "\n",
    "print(f\"Las palabras a filtrar son:\\n{palabras_a_filtrar}\\n\")\n",
    "print(f\"Se pasara de {df_lema.shape[0]} a {cambio_en_palabras} palabras\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Por lo tanto, se puede ver una disminucion considerable en la cantidad de palabras a analizar\n",
    "en cada modelo predictivo.\n",
    "\n",
    "- El filtro de palabras se aplicara en el objeto CountVectorizer con el parametro vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = CountVectorizer(stop_words=\"english\", vocabulary=LISTA_PALABRAS_A_DEJAR).fit_transform(\n",
    "    df[\"procesados_lema\"]\n",
    ")\n",
    "y = aux.codificar_sentimientos(df[\"sentiment\"])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.335, random_state=1)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resumen\n",
    "\n",
    "En la siguiente tabla se puede observar la diferencia en desempeno entre el modelo con las palabras\n",
    "filtradas por frecuencia y el que carece de tal filtro:\n",
    "\n",
    "|Metrica|Modelo Con Filtro|Modelo Sin Filtro|\n",
    "|-------|-----------------|-----------------|\n",
    "Mejor Accuracy en Entrenamiento|0.67|0.67|\n",
    "Mejor Accuracy en Validacion|0.67|0.67|\n",
    "ROC en Validacion|0.67|0.67|\n",
    "\n",
    "Se observa que tanto el modelo filtrado, como el modelo sin filtro presentan resultados identicos \n",
    "(metricas redondeadas a 2 cifras decimales). Esta tendencia se observa tanto en el conjunto de datos\n",
    "de entrenamiento, como en el conjunto de datos de validacion.\n",
    "\n",
    "Por lo tanto, **se utilizara el modelo con el filtro de palabras, ya que reduce considerablemente\n",
    "el costo computacional, y es mucho mas parsimonioso**."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importacion de Modelos Entrenados\n",
    "\n",
    "Debido a que se entrenaron todos los modelos en el Hito 2, se procedera a importar cada uno de los\n",
    "modelos ya entrenados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "archivos_a_leer = [\n",
    "    \"modelo_logistic.pickle\",\n",
    "    \"modelo_naive_bayes.pickle\",\n",
    "    \"modelo_arbol.pickle\",\n",
    "    \"modelo_random_forest.pickle\",\n",
    "    \"modelo_gradient_boosting.pickle\",\n",
    "]\n",
    "\n",
    "modelos = {}\n",
    "for nombre_archivo in archivos_a_leer:\n",
    "    with open(nombre_archivo, \"rb\") as file:\n",
    "        modelo = pickle.load(file)\n",
    "        modelos[nombre_archivo.split(\".\")[0]] = modelo\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reporte comparativo de desempenos\n",
    "\n",
    "En el Hito 2 se reportaron los desempenos de cada uno de los modelos ya entrenados. Esto se realizo\n",
    "tanto para el conjunto de entrenamiento y el conjunto de validacion. En la siguiente tabla se\n",
    "recopila a modo de resumen los resultados.\n",
    "\n",
    "|Modelo|Entrenamiento Accuracy|Validacion Accuracy|Validacion ROC|\n",
    "|------|----------------------|-------------------|--------------|\n",
    "|Logistico|0.67|0.68|0.68|\n",
    "|Naive Bayes|0.67|0.68|0.68|\n",
    "|Arbol de clasificacion|0.57|0.57|0.56|\n",
    "|Random Forest|0.66|0.66|0.65|\n",
    "|Gradient Boosting|0.66|0.67|0.66|\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Se puede observar que los mejores modelos de clasificacion (segun el valor ROC) fueron el\n",
    "modelo de regresion logistica o naive bayes. Ambos modelos presentaron un desempeno identico,\n",
    "tanto en el conjunto de entrenamiento como en el de validacion. Ademas, fueron los modelos que\n",
    "tuvieron el menor coste computacional, demorando ~8 y ~2 segundos en entrenar, respectivamente.\n",
    "\n",
    "- El peor modelo fue el arbol de clasificacion, con un valor de ROC de 0.56. Por lo tanto, clasifica\n",
    "en 6% mejor que un clasificador aleatorio.\n",
    "\n",
    "- El modelo de Random Forest y Gradient Boosting fueron los modelos mas costosos computacionalmente,\n",
    "demorando ~3 y ~9 minutos en entrenar, respectivamente. A pesar de su alto costo computacional,\n",
    "estos modelos tuvieron un resultado comparable (levemente peor) al modelo logistico o naive bayes.\n",
    "\n",
    "- El valor ROC promedio de los 5 modelos fue de 0.65."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exportacion de Mejores Modelos\n",
    "\n",
    "Teniendo en cuenta los resultados anteriores, los mejores modelos son el modelo de regresion\n",
    "logistica y naive bayes. Por lo tanto, ambos seran exportados para validacion externa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelos_a_exportar = {\n",
    "    \"modelo_1_modelo_logistico.pickle\": modelos[\"modelo_logistic\"],\n",
    "    \"modelo_2_modelo_naive_bayes.pickle\": modelos[\"modelo_naive_bayes\"],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for archivo, modelo in modelos_a_exportar.items():\n",
    "    with open(archivo, \"wb\") as file:\n",
    "        pickle.dump(modelo, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
