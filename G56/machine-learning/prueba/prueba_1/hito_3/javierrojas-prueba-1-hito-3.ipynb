{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_style()\n",
    "plt.rcParams[\"figure.figsize\"] = (20, 10)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelacion"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizacion"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Como se menciono en el enunciado, se filtraran todas las palabras que tengan una frecuencia menor\n",
    "al 0.04% de la cantidad de textos en el dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "largo_df = df.shape[0]\n",
    "filtro_frecuencias = int(round(largo_df * 0.0004, 0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Las palabras a filtrar son:\n",
      "            palabra  conteo\n",
      "2006             ½ï      11\n",
      "2007             dh      11\n",
      "2008             pa      11\n",
      "2009           melt      11\n",
      "2010         centre      11\n",
      "...             ...     ...\n",
      "37676    hysterical       1\n",
      "37677     hypocrite       1\n",
      "37678  hypnoticzexy       1\n",
      "37679      hypnosis       1\n",
      "37680     lilmickee       1\n",
      "\n",
      "[35675 rows x 2 columns]\n",
      "\n",
      "Se pasara de 37681 a 2006 palabras\n"
     ]
    }
   ],
   "source": [
    "palabras_a_filtrar = df_lema.query(\"conteo < @filtro_frecuencias\")\n",
    "palabras_restantes = df_lema.query(\"conteo >= @filtro_frecuencias\")\n",
    "cambio_en_palabras = df_lema.shape[0] - palabras_a_filtrar.shape[0]\n",
    "LISTA_PALABRAS_A_DEJAR = set(palabras_restantes.palabra.to_list())\n",
    "\n",
    "print(f\"Las palabras a filtrar son:\\n{palabras_a_filtrar}\\n\")\n",
    "print(f\"Se pasara de {df_lema.shape[0]} a {cambio_en_palabras} palabras\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Por lo tanto, se puede ver una disminucion considerable en la cantidad de palabras a analizar\n",
    "en cada modelo predictivo. Se espera una disminucion importante en el costo computacional.\n",
    "\n",
    "- El filtro de palabras se aplicara en el objeto CountVectorizer con el parametro vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = CountVectorizer(\n",
    "    stop_words=\"english\", vocabulary=LISTA_PALABRAS_A_DEJAR\n",
    ").fit_transform(df[\"procesados_lema\"])\n",
    "y = aux.codificar_sentimientos(df[\"sentiment\"])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.335, random_state=1\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Por lo tanto, se puede ver una disminucion considerable en la cantidad de palabras a analizar\n",
    "en cada modelo predictivo. Se espera una disminucion importante en el costo computacional.\n",
    "\n",
    "- El filtro de palabras se aplicara en el objeto CountVectorizer con el parametro vocabulary."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importacion de Modelos Entrenados\n",
    "\n",
    "Debido a que se entrenaron todos los modelos en el Hito 2, se procedera a importar cada uno de los\n",
    "modelos ya entrenados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "archivos_a_leer = [\n",
    "    \"modelo_logistic.pickle\",\n",
    "    \"modelo_naive_bayes.pickle\",\n",
    "    \"modelo_arbol.pickle\",\n",
    "    \"modelo_random_forest.pickle\",\n",
    "    \"modelo_gradient_boosting.pickle\",\n",
    "]\n",
    "\n",
    "modelos = {}\n",
    "for nombre_archivo in archivos_a_leer:\n",
    "    with open(nombre_archivo, \"rb\") as file:\n",
    "        modelo = pickle.load(file)\n",
    "        modelos[nombre_archivo.split(\".\")[0]] = modelo"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reporte comparativo de desempenos\n",
    "\n",
    "En el Hito 2 se reportaron los desempenos de cada uno de los modelos ya entrenados. Esto se realizo\n",
    "tanto para el conjunto de entrenamiento y el conjunto de validacion. En la siguiente tabla se\n",
    "recopila a modo de resumen los resultados.\n",
    "\n",
    "|Modelo|Entrenamiento Accuracy|Validacion Accuracy|Validacion ROC|\n",
    "|------|----------------------|-------------------|--------------|\n",
    "|Logistico|0.67|0.68|0.68|\n",
    "|Naive Bayes|0.67|0.68|0.68|\n",
    "|Arbol de clasificacion|0.57|0.57|0.56|\n",
    "|Random Forest|0.66|0.66|0.65|\n",
    "|Gradient Boosting|0.66|0.67|0.66|\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Se puede observar que los mejores modelos de clasificacion (segun el valor ROC) fueron el\n",
    "modelo de regresion logistica o naive bayes. Ambos modelos presentaron un desempeno identico,\n",
    "tanto en el conjunto de entrenamiento como en el de validacion. Ademas, fueron los modelos que\n",
    "tuvieron el menor coste computacional, demorando ~8 y ~2 segundos en entrenar, respectivamente.\n",
    "\n",
    "- El peor modelo fue el arbol de clasificacion, con un valor de ROC de 0.56. Por lo tanto, clasifica\n",
    "en 6% mejor que un clasificador aleatorio.\n",
    "\n",
    "- El modelo de Random Forest y Gradient Boosting fueron los modelos mas costosos computacionalmente,\n",
    "demorando ~3 y ~9 minutos en entrenar, respectivamente. A pesar de su alto costo computacional,\n",
    "estos modelos tuvieron un resultado comparable (levemente peor) al modelo logistico o naive bayes.\n",
    "\n",
    "- El valor ROC promedio de los 5 modelos fue de 0.65."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exportacion de Mejores Modelos\n",
    "\n",
    "Teniendo en cuenta los resultados anteriores, los mejores modelos son el modelo de regresion\n",
    "logistica y naive bayes. Por lo tanto, ambos seran exportados para validacion externa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelos_a_exportar = {\n",
    "    'modelo_1_modelo_logistico.pickle': modelos['modelo_logistic'],\n",
    "    'modelo_2_modelo_naive_bayes.pickle': modelos['modelo_naive_bayes'],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for archivo, modelo in modelos_a_exportar.items():\n",
    "    with open(archivo, 'wb') as file:\n",
    "        pickle.dump(modelo, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
