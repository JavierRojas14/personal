{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensores\n",
    "\n",
    "Aqui vimos los tensores, que basicamente son estructuras de datos como las tablas, pero\n",
    "que pueden llegar a varias dimensiones.\n",
    "\n",
    "- Se implementan con numpy\n",
    "- Tienen operaciones elemento a elemento, o a nivel de matriz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([0])\n",
    "\n",
    "# Este es un tensor de dimension 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([1, 2, 3])\n",
    "\n",
    "# Este es un tensor de dimension 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3],\n",
       "       [1, 2, 3]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([[1, 2, 3], [1, 2, 3]])\n",
    "\n",
    "# Este es un tensor de dimension 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[1 2 3]\n",
      "  [1 2 3]]\n",
      "\n",
      " [[1 2 3]\n",
      "  [1 2 3]]]\n",
      "(2, 2, 3)\n"
     ]
    }
   ],
   "source": [
    "tres = np.array([[[1, 2, 3], [1, 2, 3]], [[1, 2, 3], [1, 2, 3]]])\n",
    "\n",
    "print(tres)\n",
    "print(tres.shape)\n",
    "\n",
    "\n",
    "# Este es un tensor de dimension 3. (Es como una matriz de forma 2, 3, pero con 2 hojas!)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementacion\n",
    "\n",
    "Ocupa TensorFlow (para ocupar tensores) y Keras (Permite ocupar tensorflow de forma mas facil)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Terminos de redes Neuronales\n",
    "\n",
    "## Perceptron\n",
    "\n",
    "Fue la primera neurona que se utilizo! Hace mushosanios\n",
    "\n",
    "## Anatomia de un Perceptron\n",
    "\n",
    "Tiene neuronas. Las neuronas reciben un input, y dan un output. \n",
    "\n",
    "1. Como input reciben una serie de atributos (por ej: estatura, calorias comidas, alimentos comidos, etc), multiplicados por pesos aleatorios.\n",
    "\n",
    "2. Luego, la neurona recibe todo esos inputs, y luego los pasa por una funcion de activacion\n",
    "(es arbitraria, puede tomar los datos y sumarlos, multiplicarlos, etc)\n",
    "\n",
    "3. Finalmente, la neurona da el output, basado en el paso de los atributos (multiplicados por \n",
    "los pesos ALEATORIOS) por la funcion de activacion!\n",
    "\n",
    "4. Por ultimo, se calcula la funcion de perdida y se mide el desempeno del modelo (por ejemplo:\n",
    "se calcula el MAE)\n",
    "\n",
    "5. Basado en la funcion de perdida, y utilizando gradiente descendiente, se actualizan los pesos\n",
    "de cada atributo y se optimiza el modelo!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Funciones de activacion\n",
    "\n",
    "Hay varias, salen en Wkipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "print(keras.backend.backend())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()  # Esto es para general un modelo secuencial (neurona luego de neurona!)\n",
    "\n",
    "# La primera neurona del modelo!\n",
    "\n",
    "model.add(\n",
    "    Dense(\n",
    "        1,\n",
    "        activation=\"linear\", # Funcion de activacion de la neruona, en este caso lineal\n",
    "        use_bias=False, # Ignora el sesgo\n",
    "        kernel_initializer=\"uniform\", \n",
    "        input_shape=[1], # Forma en que vienen los datos\n",
    "        name=\"entrada\",\n",
    "    )\n",
    ")\n",
    "\n",
    "# Esta es la ultima nuerona del modelo!\n",
    "\n",
    "model.add(\n",
    "    Dense(\n",
    "        activation=\"linear\",\n",
    "        input_dim=1,\n",
    "        use_bias=False,\n",
    "        name='salida',\n",
    "        units=1\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
