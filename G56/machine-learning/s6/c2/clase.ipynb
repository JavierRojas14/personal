{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensores\n",
    "\n",
    "Aqui vimos los tensores, que basicamente son estructuras de datos como las tablas, pero\n",
    "que pueden llegar a varias dimensiones.\n",
    "\n",
    "- Se implementan con numpy\n",
    "- Tienen operaciones elemento a elemento, o a nivel de matriz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([0])\n",
    "\n",
    "# Este es un tensor de dimension 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([1, 2, 3])\n",
    "\n",
    "# Este es un tensor de dimension 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3],\n",
       "       [1, 2, 3]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([[1, 2, 3], [1, 2, 3]])\n",
    "\n",
    "# Este es un tensor de dimension 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[1 2 3]\n",
      "  [1 2 3]]\n",
      "\n",
      " [[1 2 3]\n",
      "  [1 2 3]]]\n",
      "(2, 2, 3)\n"
     ]
    }
   ],
   "source": [
    "tres = np.array([[[1, 2, 3], [1, 2, 3]], [[1, 2, 3], [1, 2, 3]]])\n",
    "\n",
    "print(tres)\n",
    "print(tres.shape)\n",
    "\n",
    "\n",
    "# Este es un tensor de dimension 3. (Es como una matriz de forma 2, 3, pero con 2 hojas!)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementacion\n",
    "\n",
    "Ocupa TensorFlow (para ocupar tensores) y Keras (Permite ocupar tensorflow de forma mas facil)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Terminos de redes Neuronales\n",
    "\n",
    "## Perceptron\n",
    "\n",
    "Fue la primera neurona que se utilizo! Hace mushosanios\n",
    "\n",
    "## Anatomia de un Perceptron\n",
    "\n",
    "Tiene neuronas. Las neuronas reciben un input, y dan un output. \n",
    "\n",
    "1. Como input reciben una serie de atributos (por ej: estatura, calorias comidas, alimentos comidos, etc), multiplicados por pesos aleatorios.\n",
    "\n",
    "2. Luego, la neurona recibe todo esos inputs, y luego los pasa por una funcion de activacion\n",
    "(es arbitraria, puede tomar los datos y sumarlos, multiplicarlos, etc)\n",
    "\n",
    "3. Finalmente, la neurona da el output, basado en el paso de los atributos (multiplicados por \n",
    "los pesos ALEATORIOS) por la funcion de activacion!. Luego, se llega al final de la red y se obtiene\n",
    "un output.\n",
    "\n",
    "4. Al output de toda la red se le puede calcular la funcion de perdida (MAE por ej).\n",
    "\n",
    "5. Basado en la funcion de perdida, y utilizando gradiente descendiente, se actualizan los pesos\n",
    "de cada atributo y se optimiza el modelo!\n",
    "\n",
    "## Diferencia con Boosting\n",
    "\n",
    "- En Boosting se conservan todo el camino de arboles generados hasta llegar al arbol mas optimo. Luego,\n",
    "se predice tomando en cuenta todos los arboles en el camino!\n",
    "\n",
    "- En las redes neuronales optimizamos los parametros a lo largo de muchas corrida. Sin embargo,\n",
    "cuando ya llegamos a un modelo optimo, solamente nos quedamos con ese modelo y solamente ese predice!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Funciones de activacion\n",
    "\n",
    "Hay varias, salen en Wkipedia. Pero son las funciones que tienen cada neurona, y que procesan\n",
    "los datos de input. Estas funciones generan un output, y este es el output de la neurona."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "print(keras.backend.backend())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inicializacion de los modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()  # Esto es para general un modelo secuencial (neurona luego de neurona!)\n",
    "\n",
    "# La primera neurona del modelo!\n",
    "\n",
    "model.add(\n",
    "    Dense(\n",
    "        1,\n",
    "        activation=\"linear\", # Funcion de activacion de la neruona, en este caso lineal\n",
    "        use_bias=False, # Ignora el sesgo\n",
    "        kernel_initializer=\"uniform\", \n",
    "        input_shape=[1], # Forma en que vienen los datos\n",
    "        name=\"entrada\",\n",
    "    )\n",
    ")\n",
    "\n",
    "# Esta es la ultima nuerona del modelo!\n",
    "\n",
    "model.add(\n",
    "    Dense(\n",
    "        activation=\"linear\",\n",
    "        input_dim=1,\n",
    "        use_bias=False,\n",
    "        name='salida',\n",
    "        units=1\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " entrada (Dense)             (None, 1)                 1         \n",
      "                                                                 \n",
      " salida (Dense)              (None, 1)                 1         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2\n",
      "Trainable params: 2\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import SGD\n",
    "\n",
    "model.compile(optimizer=SGD(learning_rate=0.1), loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 30\n",
    "intercept_true = 0.5\n",
    "slope_true = 1.5\n",
    "x = slope_true + np.random.rand(m, 1)\n",
    "y = intercept_true + (slope_true * x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x27b7383a230>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x, y, epochs=1000, verbose=0)\n",
    "\n",
    "# con los epochs se le dice al modelo que haga 1000 iteraciones para optimizar los parametros\n",
    "# del modelo.\n",
    "\n",
    "# Aqui solamente se optimiza un peso (solamente el de la entrada, ya que la de salida\n",
    "# carece de pesos (pasa en \"banda\" el resultado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-1.4313426]], dtype=float32), array([[-1.4313426]], dtype=float32)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.6463939728335388"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "mean_absolute_error(y, model.predict(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
