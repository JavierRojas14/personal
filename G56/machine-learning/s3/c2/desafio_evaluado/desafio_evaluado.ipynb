{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicio 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import glob\n",
    "import os\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "plt.style.use('seaborn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_actual = os.getcwd()\n",
    "archivos_dump = list(map(lambda x: f'{dir_actual}/{x}', glob.glob('input/dump/*.csv')))\n",
    "\n",
    "dfs = (pd.read_csv(f) for f in archivos_dump)\n",
    "df = pd.concat(dfs).drop(columns='Unnamed: 0')\n",
    "df.columns = ['artist', 'genre', 'song_name', 'lyrics']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>genre</th>\n",
       "      <th>song_name</th>\n",
       "      <th>lyrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gorgoroth</td>\n",
       "      <td>metal</td>\n",
       "      <td>Begravelsesnatt</td>\n",
       "      <td>Dypt i den mørke fjellhulen, jakt på Troll \\n ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Gorgoroth</td>\n",
       "      <td>metal</td>\n",
       "      <td>Bergtollets Hevn</td>\n",
       "      <td>Dypt i den mørke fjellhulen, jakt på Troll \\n ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gorgoroth</td>\n",
       "      <td>metal</td>\n",
       "      <td>Profetens Åpenbaring</td>\n",
       "      <td>Satan sender profetene syner \\n De før aldri h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gorgoroth</td>\n",
       "      <td>metal</td>\n",
       "      <td>The Devil Is Calling</td>\n",
       "      <td>Go out and see the churches how they are burni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gorgoroth</td>\n",
       "      <td>metal</td>\n",
       "      <td>Slottet I Det Fjerne</td>\n",
       "      <td>Kan du oyne Slottet i det fjerne \\n Og dets ly...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462</th>\n",
       "      <td>Bruce Springsteen</td>\n",
       "      <td>rock</td>\n",
       "      <td>A Night With The Jersey Devil</td>\n",
       "      <td>Hear me now! \\n I was born 13th child, 'neath ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>463</th>\n",
       "      <td>Bruce Springsteen</td>\n",
       "      <td>rock</td>\n",
       "      <td>Fun, Fun, Fun</td>\n",
       "      <td>Well she got her daddy's car \\n And she cruise...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>464</th>\n",
       "      <td>Bruce Springsteen</td>\n",
       "      <td>rock</td>\n",
       "      <td>Good Vibrations</td>\n",
       "      <td>Ah! I love the colorful clothes she wears \\n A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465</th>\n",
       "      <td>Bruce Springsteen</td>\n",
       "      <td>rock</td>\n",
       "      <td>New Jersey Is My Home</td>\n",
       "      <td>I'm proud new jersey is my home \\n Yeah said I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>Bruce Springsteen</td>\n",
       "      <td>rock</td>\n",
       "      <td>Out Of Work</td>\n",
       "      <td>8 a.m. I'm up and my feet beating on the sidew...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9489 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                artist  genre                      song_name  \\\n",
       "0            Gorgoroth  metal                Begravelsesnatt   \n",
       "1            Gorgoroth  metal               Bergtollets Hevn   \n",
       "2            Gorgoroth  metal           Profetens Åpenbaring   \n",
       "3            Gorgoroth  metal           The Devil Is Calling   \n",
       "4            Gorgoroth  metal           Slottet I Det Fjerne   \n",
       "..                 ...    ...                            ...   \n",
       "462  Bruce Springsteen   rock  A Night With The Jersey Devil   \n",
       "463  Bruce Springsteen   rock                  Fun, Fun, Fun   \n",
       "464  Bruce Springsteen   rock                Good Vibrations   \n",
       "465  Bruce Springsteen   rock          New Jersey Is My Home   \n",
       "466  Bruce Springsteen   rock                    Out Of Work   \n",
       "\n",
       "                                                lyrics  \n",
       "0    Dypt i den mørke fjellhulen, jakt på Troll \\n ...  \n",
       "1    Dypt i den mørke fjellhulen, jakt på Troll \\n ...  \n",
       "2    Satan sender profetene syner \\n De før aldri h...  \n",
       "3    Go out and see the churches how they are burni...  \n",
       "4    Kan du oyne Slottet i det fjerne \\n Og dets ly...  \n",
       "..                                                 ...  \n",
       "462  Hear me now! \\n I was born 13th child, 'neath ...  \n",
       "463  Well she got her daddy's car \\n And she cruise...  \n",
       "464  Ah! I love the colorful clothes she wears \\n A...  \n",
       "465  I'm proud new jersey is my home \\n Yeah said I...  \n",
       "466  8 a.m. I'm up and my feet beating on the sidew...  \n",
       "\n",
       "[9489 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicio 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Las 5000 palabras mas frecuentes en la base de datos son: ['000' '10' '100' ... 'zoo' 'zoom' 'zulu']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer(stop_words='english', max_features=5000)\n",
    "vectorizer_fit = vectorizer.fit_transform(df['lyrics'])\n",
    "\n",
    "words = vectorizer.get_feature_names_out()\n",
    "freqs = vectorizer_fit.toarray().sum(axis=0)\n",
    "\n",
    "print(f'Las 5000 palabras mas frecuentes en la base de datos son: {words}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicio 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_components = [5, 10, 15]\n",
    "learning_decay = [0.7, 0.5]\n",
    "\n",
    "grid = {\n",
    "    'n_components': n_components,\n",
    "    'learning_decay': learning_decay\n",
    "}\n",
    "\n",
    "modelo_grilla = GridSearchCV(LatentDirichletAllocation(learning_method='online'), \n",
    "                             param_grid=grid, verbose=5, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = CountVectorizer(stop_words='english', max_features=5000, max_df=0.1).fit_transform(df['lyrics'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "[CV 1/5] END learning_decay=0.7, n_components=5;, score=-1163788.469 total time=  35.0s\n",
      "[CV 2/5] END learning_decay=0.7, n_components=5;, score=-1473371.251 total time=  33.3s\n",
      "[CV 3/5] END learning_decay=0.7, n_components=5;, score=-1321940.552 total time=  34.2s\n",
      "[CV 4/5] END learning_decay=0.7, n_components=5;, score=-1171146.482 total time=  32.0s\n",
      "[CV 5/5] END learning_decay=0.7, n_components=5;, score=-1475996.457 total time=  30.5s\n",
      "[CV 1/5] END learning_decay=0.7, n_components=10;, score=-1180431.711 total time=  35.4s\n",
      "[CV 2/5] END learning_decay=0.7, n_components=10;, score=-1488246.542 total time=  35.0s\n",
      "[CV 3/5] END learning_decay=0.7, n_components=10;, score=-1341744.658 total time=  34.5s\n",
      "[CV 4/5] END learning_decay=0.7, n_components=10;, score=-1192856.468 total time=  34.9s\n",
      "[CV 5/5] END learning_decay=0.7, n_components=10;, score=-1493181.077 total time=  32.2s\n",
      "[CV 1/5] END learning_decay=0.7, n_components=15;, score=-1191991.383 total time=  35.9s\n",
      "[CV 2/5] END learning_decay=0.7, n_components=15;, score=-1499690.035 total time=  35.8s\n",
      "[CV 3/5] END learning_decay=0.7, n_components=15;, score=-1351902.993 total time=  32.7s\n",
      "[CV 4/5] END learning_decay=0.7, n_components=15;, score=-1210053.624 total time=  32.3s\n",
      "[CV 5/5] END learning_decay=0.7, n_components=15;, score=-1506700.706 total time=  30.1s\n",
      "[CV 1/5] END learning_decay=0.5, n_components=5;, score=-1167279.792 total time=  23.5s\n",
      "[CV 2/5] END learning_decay=0.5, n_components=5;, score=-1473713.224 total time=  20.9s\n",
      "[CV 3/5] END learning_decay=0.5, n_components=5;, score=-1320590.402 total time=  21.5s\n",
      "[CV 4/5] END learning_decay=0.5, n_components=5;, score=-1177988.119 total time=  24.0s\n",
      "[CV 5/5] END learning_decay=0.5, n_components=5;, score=-1476135.129 total time=  22.9s\n",
      "[CV 1/5] END learning_decay=0.5, n_components=10;, score=-1181386.725 total time=  23.8s\n",
      "[CV 2/5] END learning_decay=0.5, n_components=10;, score=-1491505.083 total time=  22.7s\n",
      "[CV 3/5] END learning_decay=0.5, n_components=10;, score=-1340504.120 total time=  23.2s\n",
      "[CV 4/5] END learning_decay=0.5, n_components=10;, score=-1190555.016 total time=  22.9s\n",
      "[CV 5/5] END learning_decay=0.5, n_components=10;, score=-1496732.090 total time=  22.2s\n",
      "[CV 1/5] END learning_decay=0.5, n_components=15;, score=-1190882.965 total time=  23.7s\n",
      "[CV 2/5] END learning_decay=0.5, n_components=15;, score=-1500766.732 total time=  23.7s\n",
      "[CV 3/5] END learning_decay=0.5, n_components=15;, score=-1351100.794 total time=  24.5s\n",
      "[CV 4/5] END learning_decay=0.5, n_components=15;, score=-1200480.667 total time=  25.0s\n",
      "[CV 5/5] END learning_decay=0.5, n_components=15;, score=-1502952.495 total time=  23.5s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=LatentDirichletAllocation(learning_method='online'),\n",
       "             param_grid={'learning_decay': [0.7, 0.5],\n",
       "                         'n_components': [5, 10, 15]},\n",
       "             verbose=5)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelo_grilla.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_decay': 0.7, 'n_components': 5}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelo_grilla.best_params_"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los mejores parametros para el modelo son:\n",
    "- learning_decay: 0.7\n",
    "- n_components: 5"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicio 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LatentDirichletAllocation(learning_method='online', n_components=5)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mejor_learning_decay = 0.7\n",
    "mejor_n_components = 5\n",
    "best_lda = LatentDirichletAllocation(n_components=mejor_n_components, \n",
    "                                     learning_decay=mejor_learning_decay,\n",
    "                                     learning_method='online')\n",
    "best_lda.fit(X) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tópico: 1\n",
      "ladies tony dang example nah hail yesterday round global warmth alot dope christine hol harm\n",
      "tópico: 2\n",
      "bein pages losing sunrise familiar dressed fresh forsake helped slang trust star ll figures drill\n",
      "tópico: 3\n",
      "rock roll fuse whores bridgette tool beans stretch west kissing toxic damn gin goodness bionic\n",
      "tópico: 4\n",
      "ones ah umm workout lyrics creation tan dies daisy bought humanity empire mall dancer dreams\n",
      "tópico: 5\n",
      "niggas niggaz rap funk wiz sooner bird garbage killed cheat worked vibrations goons killin chopped\n"
     ]
    }
   ],
   "source": [
    "for topic_id, topic_name in enumerate(best_lda.components_):\n",
    "# para cada tópico\n",
    "    print(\"tópico: {}\".format(topic_id + 1))\n",
    "    print(\" \".join([vectorizer.get_feature_names_out()[i] for i in\n",
    "    topic_name.argsort()[:-15 - 1: -1]]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- El primer topico pareciera corresponder a unos cuantos toques de hip-hop (por las palabras: ladies,\n",
    "tony, dang, nah, yesterday, alot, dope, hol y harm) con pop (hail, round, global, warmth). Por lo\n",
    "tanto, podria corresponder a un genero de pop con grandes influencias de hip hop.\n",
    "\n",
    "- El segundo topico pareciera corresponder a algo de rap (por las palabras: bein, pages, losing,\n",
    "sunrise, familiar, dressed, fresh, slang) con pop (familiar, dressed, helped, trust, star, figures).\n",
    "Por lo tanto, podria ser hip hop con algo de pop.\n",
    "\n",
    "- El tercer topico pareciera corresponder mas al genero de rock (por las palabras: rock, roll, fuse,\n",
    "whores, bridgette, west, kissing, toxic, damn), con un poquito de country (bridgette, tool, beans)\n",
    "y pop (bionic, goodness). Por lo tanto podria corresponder a un genero rock-country-pop.\n",
    "\n",
    "- El cuarto topico pareciera corresponder a un poco de pop (ones, ah, umm, workout, daisy, mall,\n",
    "dancer, dreams) con metal (creation, dies, humanity, empire). Por lo tanto, es un genero metal-pop,\n",
    "o metal con un poco de letras mas cotidianas.\n",
    "\n",
    "- El quinto topico pareciera ser en su gran mayoria rap (por las palabras: n****s/z, rap, funk, wiz,\n",
    "garbage, killed, cheat, goons, killin y chopped). Por lo tanto, es un genero de rap mas puro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a677eee07fae7a05dc0065b321405b89ac79028a918e58c71b412840ee16c11e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
