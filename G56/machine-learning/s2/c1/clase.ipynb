{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Motivacion\n",
    "\n",
    "Existen variadas formas de implementar modelos de clasificacion. Aqui veremos los generativos y discriminativos\n",
    "\n",
    "## Discriminativos\n",
    "\n",
    "La funcion logistica es uno tipo de algoritmo discriminativo. Aqui se utiliza una funcion que traza una frontera entre dos grupos de puntos y los diferencia. Hay un frente/linea de decision\n",
    "\n",
    "## Generativos\n",
    "\n",
    "Lo primero que hacen es agrupar los tipos de datos similares, y luego buscan caracteristicas similares entre elementos de un mismo grupo. Los generativos son mas flexibles en lo que podemos ingresar, y tienen mas ventajas con los discriminativos"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Teorema de Bayes\n",
    "\n",
    "Tiene que ver con la probabilidad condicional. \n",
    "\n",
    "- Por ejemplo: **Cual es la probabilidad de que le guste a alguien que me sonrie?**\n",
    "\n",
    "En este caso se quiere ver la probabilidad del evento \"Que le guste a alguien\", condicionado a que esa persona me sonria.\n",
    "\n",
    "Este teorema nos permite agregar informacion a nuestro analisis!\n",
    "\n",
    "Existe toda una teoria del teorema de Bayes, pero estaba confusa.\n",
    "\n",
    "$Pr(A posteriori) = \\frac{Pr(Verosimilitud) x Pr(A priori)}{Pr(Evidencia)}$\n",
    "\n",
    "Esa es la formula del Teorema de Bayes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pero llevado al problema nuestro (de si le gusta o no). Nuestro problema es saber si yo le gusto a una persona. Sin embargo, yo estoy condicionando ese evento al 2do evento, que es que alguien me sonria. Por lo tanto, definiendo esto, en la formula seria:\n",
    "\n",
    "$Pr(A Posteriori) = Pr(Le guste|Me Sonrie)$\n",
    "\n",
    "$Pr(Verosimilitud) = Pr(Me Sonrie|Le guste)$ O sea, al final la verosimilitud es el evento inverso al que queremos buscar. Dicho en otras palabras del ejemplo, es: \"Cual es la probabilidad de que una persona me sonria, si es que le gusto\". Este probabilidad la podemos estimar\n",
    "\n",
    "$Pr(A Priori) = Pr(Le guste)$ O sea, la probabilidad a priori, es la probabilidad de que mi evento principal ocurra por si solo. Esto se puede obtener de estudios u otras fuentes.\n",
    "\n",
    "$Pr(Evidencia) = Pr(Sonrie)$ O sea, la probabilidad de la evidencia es la probabilidad de que alguien me sonria aleatoriamente. Esto se puede obtener de estudios u otras fuentes.\n",
    "\n",
    "Por lo tanto para el ejemplo:\n",
    "\n",
    "$Pr(Le Guste|Me Sonria) = \\frac{Pr(Me Sonria|Le guste) x Pr(Le Guste)}{Pr(Me Sonria)}$\n",
    "\n",
    "Lo que se puede parafrasear como: \"La probabilidad de que a alguien le guste, y que me haya sonreido es igual a la probabilidad de que me sonria, cuando esa persona yo le guste, multiplicado por la probabilidad de que yo le guste y dividido por la probabilidad de que alguien me sonria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bayes_solver(likelihood=0.95, priori=0.01, evidence=0.1):\n",
    "    return round(likelihood * priori/ evidence, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.095"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bayes_solver()\n",
    "# Con los parametros default significaria:\n",
    "# La probabilidad de que me sonria alguien que le guste es del 95%\n",
    "# La probabilidad de que a una persona aleatoria le guste otra persona es del 1%\n",
    "# La probabilidad de que una persona sonria aleatoriamente es del 10%\n",
    "# Por lo tanto, la probabilidad de que le guste a alguien que me sonria es del 9.5%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.047"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Que pasaria si la persona tiende a sonreir mas del promedio?\n",
    "# La probabilidad de que le guste baja aun mas!\n",
    "bayes_solver(evidence=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.95"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Que pasaria si es que a la persona le gustan mas persona que el promedio? Que pasa\n",
    "# si a la persona le gusta el 20% de las personas que ve?\n",
    "# Y que pasaria si la persona tiende a sonreir mas que el comun de la gente?\n",
    "bayes_solver(priori=0.2, evidence=0.2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Formulacion del algoritmo Bayes ingenuo\n",
    "\n",
    "A modo de recordatorio, la formula del teorema de bayes es:\n",
    "\n",
    "Pr(A posteriori) = Pr(Inverso de nuestro evento/Likelihood) * Pr(A priori)/ Pr(Evidencia)\n",
    "\n",
    "En el caso del problema: \"Cual es la probabilidad de que le guste a alguien que me sonria?\" las variables son:\n",
    "\n",
    "Pr(Le guste|Me Sonrie) = Pr(Me Sonria|Le Gusto) * Pr(Gustarle a alguien aleatorio) / Pr(Sonria aleatoriamente)\n",
    "\n",
    "O sea, si es que la persona sonrie mas veces aleatoriamente, significa que es mucho menos probable que le guste!. Esto tiene sentido, ya que sonrie mas veces, y por lo tanto puede sonreir por muchas mas diversas razones que le guste.\n",
    "\n",
    "A diferencia, si a la persona le gustan mas personas en general, entonces aumentan las chances de que le guste!\n",
    "\n",
    "## Bayes Ingenuo en datos\n",
    "\n",
    "En un conjunto de datos cada uno de los parametros tiene una significancia y se calcula. Ademas, en el algoritmo queremos maximizar nuestra Pr(A posteriori). Esto significa que se debe aumentar el numerador del a posteriori, o sea:\n",
    "\n",
    "- Aumentar la probabilidad de mi evento a priori (En el caso anterior, aumentar las probabilidades de que a esa persona le guste alguien). **En un conjunto de datos, el a priori se calcula como la probabilidad de ocurrencia de cada clase! (Frecuencia/Total)**\n",
    "\n",
    "- Aumentar la probabilidad del likelihood (En el caso anterior, aumentar las probabilidades de que sonria si es que le gusta alguien). En un conjunto de datos, el likelihood es la frecuencia relativa de una clase y un atributo. Esto hace que el algoritmo sea ingenuo!\n",
    "\n",
    "- Disminuir la probabilidad de la evidencia (En el caso anterior, disminuir la probabilidad de que la persona sonria usualmente)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementacion de Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "plt.style.use('seaborn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
