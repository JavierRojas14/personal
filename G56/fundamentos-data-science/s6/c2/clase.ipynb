{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clase"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Los prediccion de datos continuos es medida a traves del error cuadratico medio. En la prediccion de datos clasificados, lo que se quiere aumentar es la cantidad de datos correctamente predichos (cantidad de verdaderos positivos y verdaderos negativos), y reducir la cantidad de datos erronamente predichos (cantidad de falsos positivos y falsos negativos)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>dist100</th>\n",
       "      <th>arsenic</th>\n",
       "      <th>educ4</th>\n",
       "      <th>assoc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.16826</td>\n",
       "      <td>2.36</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.47322</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.20967</td>\n",
       "      <td>2.07</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.21486</td>\n",
       "      <td>1.15</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.40874</td>\n",
       "      <td>1.10</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   y  dist100  arsenic  educ4  assoc\n",
       "0  1  0.16826     2.36    0.0      0\n",
       "1  1  0.47322     0.71    0.0      0\n",
       "2  0  0.20967     2.07    2.5      0\n",
       "3  1  0.21486     1.15    3.0      0\n",
       "4  1  0.40874     1.10    3.5      1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import lec6_graphs as gfx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "plt.style.use('seaborn')\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "\n",
    "df = pd.read_csv('wells.csv').drop(columns='index')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X = df.drop(columns='y')\n",
    "y = df['y']\n",
    "\n",
    "X_train_pre, X_test_pre, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=11238)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqui se utiliza StandarScaler (Que hace dato nuevo = dato antiguo - media de donde viene el dato / std de donde viene el dato), para tener un modelo mas uniforme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler().fit(X_train_pre)\n",
    "\n",
    "X_train = scaler.transform(X_train_pre)\n",
    "X_test = scaler.transform(X_test_pre)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.33266754,  0.5907759 ,  0.14256382, -0.05195545]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression().fit(X_train, y_train)\n",
    "model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat = model.predict(X_test)\n",
    "yhat[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.67496862, 0.32503138],\n",
       "       [0.33455362, 0.66544638],\n",
       "       [0.09020209, 0.90979791],\n",
       "       [0.70352108, 0.29647892],\n",
       "       [0.4038352 , 0.5961648 ],\n",
       "       [0.45532677, 0.54467323],\n",
       "       [0.30957084, 0.69042916],\n",
       "       [0.35040536, 0.64959464],\n",
       "       [0.4552455 , 0.5447545 ],\n",
       "       [0.46802757, 0.53197243],\n",
       "       [0.45140063, 0.54859937],\n",
       "       [0.41529136, 0.58470864],\n",
       "       [0.21485762, 0.78514238],\n",
       "       [0.60828943, 0.39171057],\n",
       "       [0.57261071, 0.42738929],\n",
       "       [0.58069364, 0.41930636],\n",
       "       [0.53925461, 0.46074539],\n",
       "       [0.43370276, 0.56629724],\n",
       "       [0.40139424, 0.59860576],\n",
       "       [0.40709762, 0.59290238]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat_prob = model.predict_proba(X_test)\n",
    "yhat_prob[:20]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediccion con el Modelo Logistico\n",
    "\n",
    "Hay 2 formas de predecir con un modelo logistico por machine learning:\n",
    "\n",
    "1. Prediccion por clasificacion: con model.predict()\n",
    "2. Prediccion por probabilidad: con model.predict_proba(). Aqui se obtiene la probabilidad de obtener cada una de las categorias entregadas (probabilidad de obtener la categoria 0, 1, etc)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metricas de Desempeno\n",
    "\n",
    "Hay 2 formas de determinar que tan bueno es nuestro modelo de clasificacion:\n",
    "\n",
    "1. Prediccion de probabilidad continua\n",
    "2. Prediccion de clase: Donde se ve la cantidad de falsos positivos y falsos negativos\n",
    "\n",
    "Se ocupa mucho mas la prediccion de clase en estos tipos de modelos!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matriz de Confusion\n",
    "\n",
    "Permite ver la cantidad de observaciones predichas y la cantidad de observaciones reales. La forma de la matriz de confusion es la siguiente:\n",
    "\n",
    "-|Categoria Verdadera| -\n",
    "--|------|---\n",
    "**Prediccion**|Verdadero|Falso\n",
    "Positivo|Verdadero Positivo|Falso Positivo\n",
    "Negativo|Falso Negativo|Verdadero \n",
    "\n",
    "En la diagonal de izq a derecha estan los valores reales. En los otros los falsos. Un Falso positivo, es un valor que fue predicho positivo, pero que en verdad es negativo. Un falso negativo, es un valor que fue predicho negativo, pero que en verdad es positivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[174, 248],\n",
       "       [120, 455]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "m1_confusion = confusion_matrix(y_test, yhat)\n",
    "m1_confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a677eee07fae7a05dc0065b321405b89ac79028a918e58c71b412840ee16c11e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
